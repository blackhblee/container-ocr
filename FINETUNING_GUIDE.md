# Florence-2 ì»¨í…Œì´ë„ˆ OCR íŒŒì¸íŠœë‹ ê°€ì´ë“œ

## ğŸ“‹ ì¤€ë¹„ ì‚¬í•­

Florence-2ë¥¼ ì»¨í…Œì´ë„ˆ ë²ˆí˜¸ ì¸ì‹ì— íŠ¹í™”ì‹œí‚¤ê¸° ìœ„í•œ LoRA íŒŒì¸íŠœë‹ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ¯ 1ë‹¨ê³„: í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements_finetune.txt
```

## ğŸ“ 2ë‹¨ê³„: ë°ì´í„°ì…‹ ì¤€ë¹„

### 2-1. Annotation í…œí”Œë¦¿ ìƒì„±

```bash
python prepare_dataset.py --mode create_template --image_folder ./image --annotation_file annotations.json
```

ì´ ëª…ë ¹ì€ `annotations.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤. ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

```json
{
  "images": [
    {
      "image_path": "image/000207_LEFT_1.jpg",
      "container_number": "TODO",
      "owner_code": "TODO",
      "serial_number": "TODO",
      "check_digit": "TODO"
    }
  ]
}
```

### 2-2. ìˆ˜ë™ìœ¼ë¡œ ë¼ë²¨ë§

`annotations.json` íŒŒì¼ì„ ì—´ê³  ê° ì´ë¯¸ì§€ë¥¼ ë³´ë©´ì„œ ì‹¤ì œ ì»¨í…Œì´ë„ˆ ë²ˆí˜¸ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤:

```json
{
  "image_path": "image/000207_LEFT_1.jpg",
  "container_number": "TEMU 1234567 0",
  "owner_code": "TEMU",
  "serial_number": "1234567",
  "check_digit": "0"
}
```

**ì¤‘ìš”**:

- ì •í™•í•œ ë¼ë²¨ë§ì´ í•™ìŠµ ì„±ëŠ¥ì˜ í•µì‹¬ì…ë‹ˆë‹¤
- ìµœì†Œ 50-100ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë¼ë²¨ë§í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤
- ë‹¤ì–‘í•œ ê°ë„ì™€ ì¡°ëª… ì¡°ê±´ì˜ ì´ë¯¸ì§€ë¥¼ í¬í•¨ì‹œí‚¤ì„¸ìš”

### 2-3. í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±

```bash
python prepare_dataset.py --mode prepare --annotation_file annotations.json --output_dir ./dataset
```

ì´ ëª…ë ¹ì€:

- `dataset/train.json`: í•™ìŠµ ë°ì´í„° (80%)
- `dataset/val.json`: ê²€ì¦ ë°ì´í„° (20%)

ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸš€ 3ë‹¨ê³„: LoRA íŒŒì¸íŠœë‹

### ê¸°ë³¸ í•™ìŠµ

```bash
python finetune_florence.py \
  --train dataset/train.json \
  --val dataset/val.json \
  --output ./florence-container-lora \
  --epochs 10 \
  --batch_size 2 \
  --lr 1e-4 \
  --device mps
```

### íŒŒë¼ë¯¸í„° ì„¤ëª…

- `--epochs`: í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸: 10)
- `--batch_size`: ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •, ê¸°ë³¸: 2)
- `--lr`: í•™ìŠµë¥  (ê¸°ë³¸: 1e-4)
- `--device`: ë””ë°”ì´ìŠ¤ (cuda/mps/cpu)

### ì˜ˆìƒ í•™ìŠµ ì‹œê°„

- 100ê°œ ì´ë¯¸ì§€, 10 epochs, MPS: ì•½ 30-60ë¶„
- CUDA GPU ì‚¬ìš© ì‹œ ë” ë¹ ë¦„

## ğŸ“ 4ë‹¨ê³„: íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì‚¬ìš©

`container_ocr.py`ë¥¼ ìˆ˜ì •í•˜ì—¬ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
from peft import PeftModel

# ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
base_model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Florence-2-large",
    trust_remote_code=True,
    attn_implementation="eager"
)

# LoRA ì–´ëŒ‘í„° ë¡œë“œ
model = PeftModel.from_pretrained(base_model, "./florence-container-lora")
model = model.to(device)
```

ë˜ëŠ” ìƒˆë¡œìš´ í´ë˜ìŠ¤ ë§Œë“¤ê¸°:

```python
class FinetunedContainerOCR(ContainerOCR):
    def __init__(self, lora_path: str = "./florence-container-lora"):
        """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì‚¬ìš©"""
        # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™” ìŠ¤í‚µí•˜ê³  ì§ì ‘ êµ¬í˜„
        from peft import PeftModel

        self.device = "mps" if torch.backends.mps.is_available() else "cpu"

        # í”„ë¡œì„¸ì„œ ë¡œë“œ
        self.processor = AutoProcessor.from_pretrained(
            "microsoft/Florence-2-large",
            trust_remote_code=True
        )

        # ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
        base_model = AutoModelForCausalLM.from_pretrained(
            "microsoft/Florence-2-large",
            trust_remote_code=True,
            attn_implementation="eager"
        )

        # LoRA ì ìš©
        self.model = PeftModel.from_pretrained(base_model, lora_path)
        self.model = self.model.to(self.device)
        self.model.eval()
```

## ğŸ“Š 5ë‹¨ê³„: ì„±ëŠ¥ í‰ê°€

íŒŒì¸íŠœë‹ í›„ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤:

```bash
# ê¸°ë³¸ ëª¨ë¸
python batch_process.py ./image --output results_base.txt

# íŒŒì¸íŠœë‹ ëª¨ë¸ (container_ocr.py ìˆ˜ì • í›„)
python batch_process.py ./image --output results_finetuned.txt
```

## ğŸ’¡ íŒ

### ë°ì´í„°ì…‹ í¬ê¸°

- ìµœì†Œ: 50ê°œ ì´ë¯¸ì§€
- ê¶Œì¥: 100-200ê°œ ì´ë¯¸ì§€
- ìµœì : 500ê°œ ì´ìƒ ì´ë¯¸ì§€

### ë°ì´í„° ë‹¤ì–‘ì„±

- ë‹¤ì–‘í•œ ê°ë„ (ì •ë©´, ì¸¡ë©´, ìœ„)
- ë‹¤ì–‘í•œ ì¡°ëª… (ë°ìŒ, ì–´ë‘ì›€)
- ë‹¤ì–‘í•œ ì»¨í…Œì´ë„ˆ ì¢…ë¥˜
- ë‹¤ì–‘í•œ ê±°ë¦¬ (ê°€ê¹Œì´, ë©€ë¦¬)

### í•™ìŠµ ëª¨ë‹ˆí„°ë§

í•™ìŠµ ë¡œê·¸ì—ì„œ `eval_loss`ê°€ ê°ì†Œí•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

```
Epoch 1: eval_loss: 2.34
Epoch 2: eval_loss: 1.89
Epoch 3: eval_loss: 1.45
...
```

### í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šìœ¼ë©´:

- learning_rate ì¡°ì • (1e-5 ~ 1e-3)
- batch_size ì¦ê°€ (ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ)
- epochs ì¦ê°€

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë©”ëª¨ë¦¬ ë¶€ì¡±**: batch_sizeë¥¼ ì¤„ì´ì„¸ìš” (1ë¡œ ì„¤ì •)
2. **ê³¼ì í•©**: ê²€ì¦ ì†ì‹¤ì´ ì¦ê°€í•˜ë©´ í•™ìŠµ ì¤‘ë‹¨
3. **ë¼ë²¨ë§ í’ˆì§ˆ**: ì •í™•í•œ ë¼ë²¨ì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤

## ğŸ”§ ë¬¸ì œ í•´ê²°

### "CUDA out of memory"

```bash
python finetune_florence.py --batch_size 1
```

### "MPS backend error"

```bash
python finetune_florence.py --device cpu
```

### í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼

- CUDA GPU ì‚¬ìš© ê¶Œì¥
- batch_size ì¦ê°€ (ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ)
- ë°ì´í„°ì…‹ í¬ê¸° ì¡°ì •

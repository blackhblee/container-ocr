"""
CSV íŒŒì¼ì„ Florence-2 íŒŒì¸íŠœë‹ìš© JSON ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜
"""

import csv
import json
from pathlib import Path
import random
from typing import List, Dict


def csv_to_florence_dataset(
    csv_file: str,
    image_folder: str,
    output_dir: str,
    train_ratio: float = 0.8,
    skip_empty: bool = True
):
    """
    CSV íŒŒì¼ì„ Florence-2 íŒŒì¸íŠœë‹ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        csv_file: CSV íŒŒì¼ ê²½ë¡œ (filename, label í˜•ì‹)
        image_folder: ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        train_ratio: í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸: 0.8)
        skip_empty: ë¹ˆ ë¼ë²¨ì„ ê°€ì§„ í•­ëª© ì œì™¸ ì—¬ë¶€ (ê¸°ë³¸: True)
    """
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True, parents=True)
    
    image_path = Path(image_folder)
    
    # CSV ì½ê¸°
    dataset = []
    skipped_count = 0
    missing_image_count = 0
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            filename = row['filename'].strip()
            label = row['label'].strip()
            
            # ë¹ˆ ë¼ë²¨ ì²˜ë¦¬
            if not label:
                if skip_empty:
                    skipped_count += 1
                    continue
                else:
                    label = "NONE"
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
            img_file = image_path / filename
            if not img_file.exists():
                print(f"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {filename}")
                missing_image_count += 1
                continue
            
            # ì»¨í…Œì´ë„ˆ ë²ˆí˜¸ íŒŒì‹±
            parts = label.split()
            if len(parts) >= 3 and parts[0] != "NONE":
                owner_code = parts[0]
                serial_number = parts[1]
                check_digit = parts[2]
            else:
                owner_code = None
                serial_number = None
                check_digit = None
            
            dataset.append({
                "image_path": str(image_path / filename),
                "container_number": label,
                "owner_code": owner_code,
                "serial_number": serial_number,
                "check_digit": check_digit
            })
    
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„:")
    print(f"   ì´ í•­ëª©: {len(dataset)}")
    print(f"   ì œì™¸ëœ ë¹ˆ ë¼ë²¨: {skipped_count}")
    print(f"   ëˆ„ë½ëœ ì´ë¯¸ì§€: {missing_image_count}")
    
    if len(dataset) == 0:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ë°ì´í„° ì…”í”Œ
    random.shuffle(dataset)
    
    # Train/Val ë¶„í• 
    split_idx = int(len(dataset) * train_ratio)
    train_data = dataset[:split_idx]
    val_data = dataset[split_idx:]
    
    # Florence-2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    train_florence = []
    for item in train_data:
        train_florence.append({
            "image": item["image_path"],
            "prefix": "<OCR>",
            "suffix": item["container_number"]
        })
    
    val_florence = []
    for item in val_data:
        val_florence.append({
            "image": item["image_path"],
            "prefix": "<OCR>",
            "suffix": item["container_number"]
        })
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    train_file = output_path / "train.json"
    val_file = output_path / "val.json"
    
    with open(train_file, 'w', encoding='utf-8') as f:
        json.dump(train_florence, f, ensure_ascii=False, indent=2)
    
    with open(val_file, 'w', encoding='utf-8') as f:
        json.dump(val_florence, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f"   í•™ìŠµ ë°ì´í„°: {len(train_florence)}ê°œ â†’ {train_file}")
    print(f"   ê²€ì¦ ë°ì´í„°: {len(val_florence)}ê°œ â†’ {val_file}")
    
    # ìƒ˜í”Œ ì¶œë ¥
    print(f"\nğŸ“ ìƒ˜í”Œ ë°ì´í„°:")
    for i, sample in enumerate(train_florence[:3]):
        print(f"   [{i+1}] {Path(sample['image']).name}: {sample['suffix']}")
    
    return train_file, val_file


def analyze_csv(csv_file: str):
    """CSV íŒŒì¼ ë¶„ì„"""
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        rows = list(reader)
    
    total = len(rows)
    with_label = sum(1 for row in rows if row['label'].strip())
    without_label = total - with_label
    
    # ìœ ë‹ˆí¬ ì»¨í…Œì´ë„ˆ ë²ˆí˜¸
    unique_containers = set()
    for row in rows:
        label = row['label'].strip()
        if label:
            unique_containers.add(label)
    
    print(f"\nğŸ“Š CSV íŒŒì¼ ë¶„ì„:")
    print(f"   ì´ í•­ëª©: {total}ê°œ")
    print(f"   ë¼ë²¨ ìˆìŒ: {with_label}ê°œ ({with_label/total*100:.1f}%)")
    print(f"   ë¼ë²¨ ì—†ìŒ: {without_label}ê°œ ({without_label/total*100:.1f}%)")
    print(f"   ìœ ë‹ˆí¬ ì»¨í…Œì´ë„ˆ ë²ˆí˜¸: {len(unique_containers)}ê°œ")
    
    # ìƒìœ„ 5ê°œ ì»¨í…Œì´ë„ˆ ë²ˆí˜¸
    if unique_containers:
        from collections import Counter
        labels = [row['label'].strip() for row in rows if row['label'].strip()]
        counter = Counter(labels)
        print(f"\nğŸ” ê°€ì¥ ë§ì€ ì»¨í…Œì´ë„ˆ ë²ˆí˜¸:")
        for label, count in counter.most_common(5):
            print(f"   {label}: {count}ê°œ")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="CSVë¥¼ Florence-2 ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜")
    parser.add_argument("--csv", type=str, required=True, help="ì…ë ¥ CSV íŒŒì¼")
    parser.add_argument("--image_folder", type=str, default="train_image", help="ì´ë¯¸ì§€ í´ë”")
    parser.add_argument("--output_dir", type=str, default="dataset", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--train_ratio", type=float, default=0.8, help="í•™ìŠµ ë°ì´í„° ë¹„ìœ¨")
    parser.add_argument("--include_empty", action="store_true", help="ë¹ˆ ë¼ë²¨ë„ í¬í•¨")
    parser.add_argument("--analyze_only", action="store_true", help="ë¶„ì„ë§Œ ìˆ˜í–‰")
    
    args = parser.parse_args()
    
    if args.analyze_only:
        analyze_csv(args.csv)
    else:
        csv_to_florence_dataset(
            csv_file=args.csv,
            image_folder=args.image_folder,
            output_dir=args.output_dir,
            train_ratio=args.train_ratio,
            skip_empty=not args.include_empty
        )
